---
title: "p8105_hw2_sp4170"
author: "Shihui Peng"
date: "2023-10-03"
output: github_document
---
```{r, message=FALSE, echo=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1
First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols_month_df =
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day")) |>
  mutate(month = recode(month, "01" = "January", "02" = "Feburary", "03" = "March", "04" = "April", "05" = "May", "06" = "June", "07" = "July", "08" = "August", "09" = "September", "10" = "October", "11" = "November", "12" = "December")) |> 
  mutate(president = ifelse(prez_gop == 0, "prez_dem", "prez_gop")) |> 
  select(year, month, gov_gop : rep_gop, gov_dem : president)

```
Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.
```{r}
snp_df =
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year")) |> 
  mutate(year = as.numeric(year)) |> 
  mutate(year = 2000 + year) |> 
  mutate(month = recode(month, "1" = "January", "2" = "Feburary", "3" = "March", "4" = "April", "5" = "May", "6" = "June", "7" = "July", "8" = "August", "9" = "September", "10" = "October", "11" = "November", "12" = "December")) |> 
  arrange(year, month) |> 
  relocate(year, month) |> 
  select(-day)
```
Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.
```{r}
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) |> 
  mutate(month = recode(month, "jan" = "January",  "feb" = "Feburary", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December"))
```
Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
pols_month_df = 
  mutate(pols_month_df, year = as.character(year))

snp_df = 
  mutate(snp_df, year = as.character(year))

unemployment_df = 
  mutate (unemployment_df, year = as.character(year))

pols_month_df_merge = 
  left_join(pols_month_df, snp_df, by = c("year", "month"))

pols_month_df_merge = 
  left_join(pols_month_df, unemployment_df, by = c("year", "month"))
```
Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset.(e.g. give the dimension, range of years, and names of key variables).

Description:

*pols_month_df*:

1. this data set is a `r nrow(pols_month_df)` rows * `r ncol(pols_month_df)` cols data set.
2. the names of variables are `r colnames(pols_month_df)`

*snp_df*:

1. this data set is a `r nrow(snp_df)` rows * `r ncol(snp_df)` cols data set.
2. the names of variables are `r colnames(snp_df)`

*unemployment_df*:

1. this data set is a `r nrow(unemployment_df)` rows * `r ncol(unemployment_df)` cols data set.
2. the names of variables are `r colnames(unemployment_df)`

*Final data set*:

1. the final data set, pols_month_df_merge, is made up of 3 original data sets, which are pols-month.csv, snp.csv, and unemployment.csv. 
2. the range of years contained in the final data set is from 1947 to 2015.
3. the final data set is a `r nrow(pols_month_df_merge)` rows * `r ncol(pols_month_df_merge)` cols data set.
4. the names of variables are `r colnames(pols_month_df_merge)`.

# problem 2

## import data sets

*Read and clean the Mr. Trash Wheel sheet:*

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* use reasonable variable names
* omit rows that do not include dumpster-specific data

The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.
```{r}
mr_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> 
  janitor::clean_names() |> 
  mutate(year = as.double(year)) |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = (500 * weight_tons)/30)
```

*Use the similar process to import, clean, and organize the data for Professor Trash Wheel*
```{r}
professor_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(year = as.double(year)) |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = (500 * weight_tons)/30)
```

*Use the similar process to import, clean, and organize the data for Gwynnda*
```{r}
gwynnda_trash_wheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(year = as.double(year)) |> 
  mutate(homes_powered = (500 * weight_tons)/30)
```

*Combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset.*

To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.
```{r}
mr_trash_wheel_df = 
  mutate(mr_trash_wheel_df, type = "mr_trash_wheel")

professor_trash_wheel_df = 
  mutate(professor_trash_wheel_df, type = "professor_trash_wheel")

gwynnda_trash_wheel_df = 
  mutate(gwynnda_trash_wheel_df, type = "gwynnda_trash_wheel")
```
then, use `bind_rows` to combine these datasets
```{r}
trash_wheel_df = 
  bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |> 
  janitor::clean_names()
```

*Write a paragraph about these data; Be sure to note the number of observations in the resulting dataset, and give examples of key variables.*

* for the data set mr_trash_wheel_df: 

  * the dimension of the final data set trash_wheel_df is **`r nrow(mr_trash_wheel_df)` rows * `r ncol(mr_trash_wheel_df)` cols**, and there are **`r nrow(mr_trash_wheel_df)`** observations in the resulting dataset.
  * the key variables are dumpster, weight_tons, homes_powered, etc. All the variables are listed as followed: **`r colnames(mr_trash_wheel_df)`**
  
* for the data set professor_trash_wheel_df:

  * the dimension of the final data set trash_wheel_df is **`r nrow(professor_trash_wheel_df)` rows * `r ncol(professor_trash_wheel_df)` cols**, and there are **`r nrow(professor_trash_wheel_df)`** observations in the resulting dataset.
  * the key variables are dumpster, weight_tons, homes_powered, etc. All the variables are listed as followed: **`r colnames(professor_trash_wheel_df)`**

* for the data set gwynnda_trash_wheel_df:

  * the dimension of the final data set trash_wheel_df is **`r nrow(gwynnda_trash_wheel_df)` rows * `r ncol(gwynnda_trash_wheel_df)` cols**, and there are **`r nrow(gwynnda_trash_wheel_df)`** observations in the resulting dataset.
  * the key variables are dumpster, weight_tons, homes_powered, etc. All the variables are listed as followed: **`r colnames(gwynnda_trash_wheel_df)`**


* for the final data set trash_wheel_df:

  * the dimension of the final data set trash_wheel_df is **`r nrow(trash_wheel_df)` rows * `r ncol(trash_wheel_df)` cols**, and there are **`r nrow(trash_wheel_df)`** observations in the resulting dataset.
  * the key variables are dumpster, weight_tons, homes_powered, etc. All the variables are listed as followed: **`r colnames(trash_wheel_df)`**
  

*For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?*

  * the total weight of trash collected by Professor Trash Wheel is **`r sum(filter(trash_wheel_df, type == "professor_trash_wheel") |> pull(weight_tons))`**
  * the total number of cigarette butts collected by Gwynnda in July of 2021 is **`r sum(filter(trash_wheel_df, type == "gwynnda_trash_wheel" & month == "July" & year == 2021) |> pull(cigarette_butts))`**



# problem 3

## import, clean, and tidy datasets

*Import, clean, and tidy the dataset of baseline demographics.  Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).*
```{r}
mci_baseline = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  filter(current_age < age_at_onset | age_at_onset == ".") |> 
  mutate(
    sex = 
      case_match(sex, 0 ~ "female", 1 ~ "male"), 
    apoe4 = 
      case_match(apoe4, 0 ~ "non-carrier", 1 ~ "carrier"))
```
*Discuss important steps in the import process and relevant features of the dataset.*

* important steps:

  * need to use `read_csv` to import csv format dataset and skip the first row with `skip = 1` because variable names have taken a whole row in the original file. here i use relative path to import.
  * need to use `janitor::clean_names()` to make sure column names are all in snake_case format.
  * need to use `filter()` to keep the rows with age_at_onset is of null value "." OR the current_age is smaller than age_at_onset, in order to meet the include criteria.
  * need to use `case_match` to recode the value of the sex column and the apoe4 column.
  
* features of the dataset mci_baseline_df.

  * there are **`r ncol(mci_baseline)` cols and `r nrow(mci_baseline)` rows** in the final data set. There are **`r nrow(mci_baseline)` observations** in the final data set.
  * the variables names are **`r colnames(mci_baseline)`**

*How many participants were recruited, and of these how many develop MCI?* 
```{r}
mci_baseline_dev = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  filter(current_age < age_at_onset & age_at_onset != ".") |> 
  mutate(
    sex = 
      case_match(sex, 0 ~ "female", 1 ~ "male"), 
    apoe4 = 
      case_match(apoe4, 0 ~ "non-carrier", 1 ~ "carrier"))
```
  * there are **`r nrow(mci_baseline)` participants** recruited in the study. Of these participants, there are **`r nrow(mci_baseline_dev)`** of participants who developed MCI.

*What is the average baseline age?*

  * the average baseline age is **`r mean(pull(mci_baseline, current_age))`**, after we filter the original data set based on the inclusion criteria "no MCI at base line".

*What proportion of women in the study are APOE4 carriers?*

  * the proportion of women in the study are APOE4 carriers is **`r nrow(filter(mci_baseline, sex == "female" & apoe4 == "carrier")) / nrow(filter(mci_baseline, sex == "female"))`.**
  
*Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values;  comment on the steps on the import process and the features of the dataset.*

```{r}
mci_amyloid_df = 
  read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names()

mci_amyloid_pivot_df = 
  pivot_longer(
    mci_amyloid_df, baseline : time_8,
    names_to = "visit",
    values_to = "amyloid",
    names_prefix = "time_"
  ) |> 
  mutate(
    visit = replace (visit, visit == "baseline", "0")
  )
  
```
*comment on the steps on the import process*

  * need to use `read_csv` to import csv format dataset and need to skip the first row with `skip = 1` because variable names have taken a whole row in the original file.
  * need to use `janitor::clean_names()` to make sure column names are all in snake_case format.
  * when tidying data:
    * need to contain all the columns that we want to tidy, which is `baseline : time_8` in this case.
    * need to use `pivot_longer` because we want the data set to go from wide format to long format. We want have a single column to represent all the time variables and another column to represent the corresponding values associated with those time variables.
    * we want to put the time variables which are included in the columns names as baseline ~ time_8 into a separate new column, and name this column as "visit" using `names_to = "visit"`. Then all the values that corresponding to the columns baseline ~ time_8 are moved to a new column named "amyloid" using `values_to = "amyloid"`.
    * we want to remove the prefix "time_" for all values in new column "visit" using `names_prefix = "time_"`
    * we want to replace the "baseline" by "0" in the new column "visit" using `mutate()` and `replace()`.


*features of the dataset mci_amyloid_pivot_df.*

  * there are **`r ncol(mci_amyloid_pivot_df)` cols and `r nrow(mci_amyloid_pivot_df)` rows** in the final data set. There are **`r nrow(mci_amyloid_pivot_df)` observations** in the final data set.
  * the variables names are **`r colnames(mci_amyloid_pivot_df)`**
  
  
## Check whether some participants appear in only the baseline or amyloid datasets

*Check whether some participants appear in only the baseline dataset, and comment on your findings.*

first, switch the "study_id" into "id" in mci_amyloid_pivot_df to make the primary key column in both data sets has the same column name "id"
```{r}
mci_amyloid_pivot_df = 
  rename(mci_amyloid_pivot_df, id = study_id)

mci_amyloid_df = 
  rename(mci_amyloid_df, id = study_id)
```
then, use anti_join to check:
```{r}
baseline_only_df = 
  anti_join(mci_baseline, mci_amyloid_pivot_df, by = "id")
```
* based on the anti_join process, there are **`r nrow(baseline_only_df)` participants** who are only appear in the baseline dataset but not appear in the amyloid dataset.


*Check whether some participants appear in only the amyloid dataset, and comment on your findings.*
```{r}
amyloid_only_df = 
  anti_join(mci_amyloid_pivot_df, mci_baseline, by = "id")
```
* based on the anti_join process, there are **`r nrow(amyloid_only_df)` observations** that are only appear in the amyloid dataset but not appear in the baseline dataset. However, since one participant has 5 records (5 time points in total, which are visit = 0, 2, 4, 6, 8) in the tidied amyloid data set, when asking for how many participants appear in only the amyloid dataset, we need to use `r nrow(amyloid_only_df)` divided by 5, which is **`r nrow(amyloid_only_df)/5` participants** are only appear in the amyloid dataset but not appear in the baseline dataset.

## combine the datasets

*Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset.*

Since i have 2 datasets for amyloid data, one for original one and the other for after-tidying one, i will try them both.

if i combine the original data sets "mci_amyloid_df" and "mci_baseline":
```{r}
baseline_amyloid_both_df = 
  inner_join(mci_amyloid_df, mci_baseline, by = "id")
```
* there are **`r nrow(baseline_amyloid_both_df)` participants** appear in both datasets "mci_amyloid_df" and "mci_baseline". the combined data set has **`r nrow(baseline_amyloid_both_df)` rows and `r ncol(baseline_amyloid_both_df)` cols**. the names of variables are **`r colnames(baseline_amyloid_both_df)`**.


if i combine the data sets after pivot_longer "mci_amyloid_pivot_df" and "mci_baseline":
```{r}
baseline_amyloid_pivot_both_df = 
  inner_join(mci_amyloid_pivot_df, mci_baseline, by = "id")
```
* there are **`r nrow(baseline_amyloid_pivot_both_df)` observations** appear in both datasets "mci_amyloid_pivot_df" and "mci_baseline". the combined data set has **`r nrow(baseline_amyloid_pivot_both_df)` rows and `r ncol(baseline_amyloid_pivot_both_df)` cols**. the names of variables are **`r colnames(baseline_amyloid_pivot_both_df)`**. However, since one participant has 5 records (5 time points in total, which are visit = 0, 2, 4, 6, 8) in the tidied amyloid data set, when asking for how many participants appear in final combined dataset, we need to use `r nrow(baseline_amyloid_pivot_both_df)` divided by 5, which is **`r nrow(baseline_amyloid_pivot_both_df)/5` participants**.

## export final data set

*export the result as a CSV to your data directory.*

export the combining dataset for "mci_amyloid_pivot_df", which is a tidied dataset, and "mci_baseline"
```{r}
write_csv(baseline_amyloid_pivot_both_df, "data/baseline_amyloid_pivot_both_df.csv")
```

export the combining dataset for "mci_amyloid_df", which is an untidied dataset, and "mci_baseline"
```{r}
write_csv(baseline_amyloid_both_df, "data/baseline_amyloid_both_df.csv")
```
